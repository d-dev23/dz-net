# Домашнее задание к занятию "6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Ответы:
1) Допустим, что средства профлирования уже были включены.
Теперь мы можем найти список запросов, выполняющихся больше 3-х минут: db.currentOp({"secs_running":{$gte: 180}}).
Найдем интересующий нас запрос.
Остановим его командой: db.killOp(opid).

2) С помощью профилировщика, как в пункте выше можно найти все запросы, попадающие под наши критерии медленных.
С помощью explain(‘executionStats’) построить план запроса.
Наиболее вероятная причина низкой скорости - выборка по большому числу записей, чтобы их сократить нужно построить индекс.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
 Ответы:
 
Рост “новых” пар ключ-значение по отношению к тем, которые должны быть очищены говорит о том, что растет размер хранилища, а значит ресурс памяти заканчивается. Блокировка на запись, скорее свего, говорит о том, то выделенная память закончилась.
Чтобы взять блокировку, клиент вычисляет, сколько времени истекло; для этого он вычитает из актуального значения времени ту метку времени, которая была получена в текущее время в миллисекундах. Тогда и только тогда, когда клиент смог получить блокировку на большинстве инстансов (как минимум 3), и общее время, понадобившееся на то, чтобы получить блокировку, меньше времени действия блокировки, считается, что получение блокировки состоялось.

Доработка:

Если в базе данных есть много ключей, срок действия которых истекает в одну и ту же секунду, и они составляют не менее 25% текущей совокупности ключей с установленным сроком действия, Redis может заблокировать, чтобы получить процент ключей, срок действия которых уже истек. ниже 25%.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

Ответы:

Чаще всего данная ситуация возникает, когда происходит выборка очень большого количества данных, что очевидно, т.к. проблема стала возникать не сразу, а при росте количества записей!
Документация рекомендует нам увеличить настройку net_read_timeout с дефолтных 30 до 60 секунд, но делать это стоит только после того, как закончились пути оптимиация запроса с помощью индексов и других средств БД.

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

Ответы:

Данная ошибка говорит о том, что закончилась выделенная память.
В двух словах, Out-Of-Memory Killer — это процесс, который завершает приложение, чтобы спасти ядро от сбоя. Он жертвует приложением, чтобы сохранить работу ОС. Случается, что у ОС нет свободной памяти, но она закрепляет память за процессом, и когда процессу она нужна, ОС выделяет ее, если может. Минус в том, что иногда ОС резервирует память, но в нужный момент свободной памяти нет, и происходит сбой системы.
Можно зарезервироватьбольше памяти для процесса через vm.overcommit_memory

0: ядро само решает, стоит ли резервировать слишком много памяти. Это значение по умолчанию в большинстве версий Linux.

1: ядро всегда будет резервировать лишнюю память. Это рискованно, ведь память может закончиться, потому что, скорее всего, однажды процессы затребуют положенное.

2: ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio

Как вариант 2 пункт.

Доработка:

Выставить once core just -1000, сделать настройку конфигурации postgres где указать наше количество ресурсов, сколько их и сколько допустимо потреблять.
А нельзя потому что oom-killer всё равно может "постучаться в двери".

Доработка №100500:

ДАНО:
Сервер 1гб ОЗУ, 15гб HDD, 1 ядра
ВЫДЕЛЯЕМ для минимизации расхода по памяти:
shared_buffers  = 256MB
work_mem = 4MB
maintenance_work_mem = 64MB
